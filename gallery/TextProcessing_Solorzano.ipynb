{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Text-Processing\" data-toc-modified-id=\"Text-Processing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Text Processing</a></div><div class=\"lev2 toc-item\"><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Introduction</a></div><div class=\"lev1 toc-item\"><a href=\"#Preparations\" data-toc-modified-id=\"Preparations-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Preparations</a></div><div class=\"lev2 toc-item\"><a href=\"#Get-fulltext-\" data-toc-modified-id=\"Get-fulltext--21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Get fulltext </a></div><div class=\"lev2 toc-item\"><a href=\"#Segment-source-text\" data-toc-modified-id=\"Segment-source-text-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Segment source text</a></div><div class=\"lev2 toc-item\"><a href=\"#Read-segments-into-a-variable-\" data-toc-modified-id=\"Read-segments-into-a-variable--23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Read segments into a variable </a></div><div class=\"lev2 toc-item\"><a href=\"#Tokenising-\" data-toc-modified-id=\"Tokenising--24\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Tokenising </a></div><div class=\"lev2 toc-item\"><a href=\"#Stemming-/-Lemmatising-\" data-toc-modified-id=\"Stemming-/-Lemmatising--25\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Stemming / Lemmatising </a></div><div class=\"lev2 toc-item\"><a href=\"#Eliminate-Stopwords-\" data-toc-modified-id=\"Eliminate-Stopwords--26\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Eliminate Stopwords </a></div><div class=\"lev1 toc-item\"><a href=\"#Characterise-passages:-TF/IDF\" data-toc-modified-id=\"Characterise-passages:-TF/IDF-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Characterise passages: TF/IDF</a></div><div class=\"lev2 toc-item\"><a href=\"#Build-vocabulary-\" data-toc-modified-id=\"Build-vocabulary--31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Build vocabulary </a></div><div class=\"lev2 toc-item\"><a href=\"#Calculate-Terms'-Text-Frequencies-(TF)-\" data-toc-modified-id=\"Calculate-Terms'-Text-Frequencies-(TF)--32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Calculate Terms' Text Frequencies (TF) </a></div><div class=\"lev2 toc-item\"><a href=\"#Normalise-TF-\" data-toc-modified-id=\"Normalise-TF--33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Normalise TF </a></div><div class=\"lev2 toc-item\"><a href=\"#Inverse-Document-Frequencies-(IDF)-and-TF-IDF-\" data-toc-modified-id=\"Inverse-Document-Frequencies-(IDF)-and-TF-IDF--34\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Inverse Document Frequencies (IDF) and TF-IDF </a></div><div class=\"lev1 toc-item\"><a href=\"#Vector-Space-Model-of-the-text-\" data-toc-modified-id=\"Vector-Space-Model-of-the-text--4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Vector Space Model of the text </a></div><div class=\"lev2 toc-item\"><a href=\"#Another-method-to-generate-the-dimensions:-n-grams-\" data-toc-modified-id=\"Another-method-to-generate-the-dimensions:-n-grams--41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Another method to generate the dimensions: n-grams </a></div><div class=\"lev2 toc-item\"><a href=\"#Extending-the-dimensions-\" data-toc-modified-id=\"Extending-the-dimensions--42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Extending the dimensions </a></div><div class=\"lev2 toc-item\"><a href=\"#Word-Clouds-\" data-toc-modified-id=\"Word-Clouds--43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Word Clouds </a></div><div class=\"lev2 toc-item\"><a href=\"#Similarity-\" data-toc-modified-id=\"Similarity--44\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Similarity </a></div><div class=\"lev2 toc-item\"><a href=\"#Clustering-\" data-toc-modified-id=\"Clustering--45\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Clustering </a></div><div class=\"lev1 toc-item\"><a href=\"#Working-with-several-languages\" data-toc-modified-id=\"Working-with-several-languages-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Working with several languages</a></div><div class=\"lev2 toc-item\"><a href=\"#Translations?\" data-toc-modified-id=\"Translations?-51\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Translations?</a></div><div class=\"lev1 toc-item\"><a href=\"#Graph-based-NLP\" data-toc-modified-id=\"Graph-based-NLP-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Graph-based NLP</a></div><div class=\"lev1 toc-item\"><a href=\"#Topic-Modelling\" data-toc-modified-id=\"Topic-Modelling-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Topic Modelling</a></div><div class=\"lev1 toc-item\"><a href=\"#Manual-Annotation\" data-toc-modified-id=\"Manual-Annotation-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Manual Annotation</a></div><div class=\"lev1 toc-item\"><a href=\"#Further-information\" data-toc-modified-id=\"Further-information-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Further information</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an introduction to some algorithms used in text analysis. While I cannot define **what questions** a scholar can ask, I can and do describe here **what kind of information** about text some popular methods can deliver. From this, you need to draw on your own research interests and creativity..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will describe methods of finding words that are characteristic for a certain passage (\"tf/tdf\"), constructing fingerprints or \"wordclouds\" for passages that go beyond the most significant words (\"word vectors\").  Of course, an important resource in text analysis is the hermeneutic interpretation of the scholar herself, so I will present a method of adding manual annotations to the text, and finally I will also say something about possible approaches to working across languages.\n",
    "\n",
    "At the moment the following topics are still waiting to be discussed: grouping passages according to their similarity (\"clustering\"), and forming an idea about different contexts being treated in a passage (\"topic modelling\"). Some more prominent approaches in the areas that have been mentioned so far are \"collocation\" analyses and the \"word2vec\" tool; I would like add discussions of these at a later moment.\n",
    "\n",
    "\"Natural language processing\" in the strict sense, i.e. analyses that have an understanding of how a language works, with its grammar, different modes, times, cases and the like, are *not* going to be covered; this implies \"stylometric\" analyses. Nor are there any discussions of \"artificial intelligence\" approaches. Maybe these can be discussed at another occasion and on another page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many of the steps discussed on this page there are ready-made tools and libraries, often with easy interfaces. But first, it is important to understand what these tools are **actually doing** and how their results are affected by the **selection of parameters** (that one can or cannot modify).\n",
    "\n",
    "And second, most of these tools expect the **input to be in some particular format**, say, a series of plaintext files in their own directory, a list of word/number)-pairs, a table or a series of integer (or floating point) numbers, etc. So, by understanding the process, you should be better prepared to provide your text to the tools in the most productive way.\n",
    "\n",
    "Finally, it is important to be aware of what information is **lost** at which point in the process. If the research requires so, one can then either look for a different tool or approach to this step (e.g. using an additional dimension in the list of words to keep both original and regularized word forms, or to remember the position of the current token in the original text), or one can compensate for the data loss (e.g. offering a lemmatised search to find occurrences after the analysis returns only normalised word forms)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The programming language used in the following examples is called \"python\" and the tool used to get prose discussion and code samples together is called \"jupyter\". In jupyter, you have a \"notebook\" that you can populate with text or code and a program that pipes a nice rendering of the notebook to a web browser. In this notebook, in many places, the output that the code samples produce is printed right below the code itself. Sometimes this can be quite a lot of output and depending on your viewing environment you might have to scroll quite some way to get to the continuation of the discussion. You can save your notebook online (the current one is [here at github](https://github.com/awagner-mainz/notebooks/blob/master/gallery/TextProcessing_Solorzano.ipynb)) and there is an online service, nbviewer, able to render any notebook that it can access online. So chances are you are reading this present notebook at the web address [https://nbviewer.jupyter.org/github/awagner-mainz/notebooks/blob/master/gallery/TextProcessing_Solorzano.ipynb](https://nbviewer.jupyter.org/github/awagner-mainz/notebooks/blob/master/gallery/TextProcessing_Solorzano.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A final word about the elements of this notebook:\n",
    "\n",
    "<div class=\"alert alertbox alert-success\">At some points I am mentioning things I consider to be important decisions or take-away messages for scholarly readers. E.g. whether or not to insert certain artefacts into the very transcription of your text, what the methodological ramifications of a certain approach or parameter are, what the implications of an example solution are, or what a possible interpretation of a certain result might be. I am highlighting these things in a block like this one here or at least in <font color=\"green\">**green bold font**</font>.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As indicated above, before doing maths, language processing tools normally expect their input to be in a certain format. First of all, you have to have an input in the first place: Therefore, a scholar wishing to experiment with such methods should avail herself of the text that should be studied, as a full transcription. This can be done by transcribing it herself, using transcriptions that are available from elsewhere, or even from OCR. (Although in the latter case, the results depend of course on the quality of the OCR output.) Second, many tools get tripped up when formatting or bibliographical metainformation is included in their input. And since the approaches presented here are not concerned with a digital edition or any other form of true representation of the source, *markup* (e.g. for bold font, heading or note elements) should be *suppressed*. (Other tools accept marked up text and strip the formatting internally.) So you should try to get a copy of the text(s) you are working with in **plaintext** format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For another detail regarding these plain text files, we have to make a short excursus, because even with plain text, there are some important aspects to consider: As you surely know, computers understand number only and as you probably also know, the first standards to encode alphanumeric characters, like ASCII, in numbers were designed for teleprinters and the reduced character set of the english language. When more extraordinary characters, like *Umlauts* or *accents* were to be encoded, one had to rely on extra rules, of which - unfortunately - there have been quite a lot. These are called \"**encodings**\" and one of the more important set of such rules are the windows encodings (e.g. CP-1252), another one is called Latin-9/ISO 8859-15 (it differs from the older Latin-1 encoding among others by including the Euro sign). Maybe you have seen web pages with garbled *Umlauts* or other special characters, then that was probably because your browser interpreted the numbers according to an encoding different from the one that the webpage author used. Anyway, the point here is that there is another standard encompassing virtually all the special signs from all languages and for a few years now, it is also supported quite well by operating systems, programming languages and linguistic tools. This standard is called \"Unicode\" and the encoding you want to use is called **utf-8**. So when you export or import your texts, try to make sure that this is what is used. ([Here](https://unicode-table.com/) is a webpage with the complete unicode table - it is loaded incrementally, so make sure to scroll down in order to get an impression of what signs this standard covers. But on the other hand, it is so extensive that you don't want to scroll through all the table...)\n",
    "\n",
    "Especially when you are coming from a windows operating system, you might have to do some searching about how to export your text to utf-8 (at one point I could make a unicode plaintext export in wordpad, only to find out after some time of desperate debugging that it was utf-*16* that I had been given. Maybe you can still find the traces of my own conversion of such files to utf-8 below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alertbox alert-success\">Also, you should consider whether or not you can replace *abbreviations* with their expanded versions in your transcription. While at some points (e.g. when lemmatising), you can associate expansions to abbreviations, the whole processing is easier when words in the text are indeed words, and periods are rather sentence punctuation than abbreviation signs. Of course, this also depends on the effort you can spend on the text...</div>\n",
    "\n",
    "This section now describes how the plaintext can further be prepared for analyses: E.g. if you want to process the *distribution* of words in the text, the processing method has to have some notion of different places in the text -- normally you don't want to manage words according to their absolute position in the whole work (say, the 6.349th word and the 3.100th one), but according to their occurrence in a particular section (say, in the third chapter, without caring too much whether it is in the 13th or in the 643th position in this chapter). So, you partition the text into meaningful segments which you can then label, compare etc.\n",
    "\n",
    "Other preparatory work includes suppressing stopwords (like \"the\", \"is\", \"of\" in english) or making the tools manage different forms of the same word or different historical writings identically. Here is what falls under this category:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. [Get fulltext](#GetFulltext)\n",
    "  2. [Segment source text](#SegmentSourceText) \n",
    "  3. [Read segments into Variable/List](#ReadSegmentsIntoVariable)\n",
    "  4. [Tokenising](#Tokenising)\n",
    "  5. [Stemming/Lemmatising](#StemmingLemmatising)\n",
    "  6. [Eliminate stopwords](#EliminateStopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get fulltext <a name=\"GetFulltext\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the examples given on this page, I am using a transcription of Juan de Solorzano's *De Indiarum Iure*, provided by Angela Ballone. Angela has inserted a special sequence of characters - \"€€€ - [&lt;Label for the section>]\" - at places where she felt that a new section or argument is beginning, so that we can segment the big source file into different sections each dealing with one particular argument. (Our first task.) But first, let's have a look at our big source file; it is in the folder \"SP_seminar\" and is called **1cap_b1_TA.txt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:11.301693Z",
     "start_time": "2017-09-12T11:48:11.271526+02:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['€€€ - [title]\\n',\n",
       " '  Caput Primum – De statu et libertate Indorum in communi; et de origine et damnatione servitii personalis eorum, quod sub tributorum colore iniuste ab aliquibus usurpatur.\\n',\n",
       " '  \\n',\n",
       " '€€€ - [Indians are free]\\n',\n",
       " '  Quae prioribus (1) illis libris scripsimus, quos nuper circa iustam harum Indiarum Occidentalium inquisitionem, acquisitionem, et retentionem luce donavimus, ea, ut ibidem advertimus, praestolantur, quae ad earundem gubernationem spectant. In quibus proponendis et exponendis, ut recto ordine procedatur, ab Indorum personis, earumque statu, et conditione initium capessemus; (2) quarum in omnibus iuris quaestionibus priorem, potioremque; inspectionem esse debere, optime docuit Iuris_Civilis in liber_2_Digesta_De_Statu_Hominum_Lex_Si_quaeremus, liber_6_Digesta_De_Testamento_Lex_Quidam_referunt, liber_14_Decretus_De_Iure_codicilli_paragraphus_ultimo, Institutiones_de_Iure_Naturalis_Lex_2_paragraphus_post_originem, De_Origine_Iure.\\n',\n",
       " '  \\n',\n",
       " '€€€ - [Primum]\\n',\n",
       " '  Et plane (3) ipsos Indos Naturali, ac Civili Iure inspecto, et seriis, ac repetitis Regum nostrorum iussionibus et schedulis liberos esse, et ut liberos tractari debere, satis luculenter probatum reliquimus in Юliber_3 prioris voluminis, Юcapitus_7 per totum et optime supponit elegantissimus pater ЖIoseph_ACOSTA liber_2_De_Procuranda_Indorum_Salute_capitus_7_pagina_235 quem ibidem numerus_53 retulimus, et iterum graviter repetit liber_3_capitus_17 sic inquiens: Atque inprimis Indos non esse servitute mulctatos, sed liberos prorsus, et sui iuris, ex iis, quae in liber_2 disputata sunt, summimus. Etenim et publicae leges ita statuunt, et consuetudo diuturna, et ratio constans, ac certa, quod qui nulla iniuria lacessunt, non possint reddi belli iure captivi.\\n',\n",
       " '  \\n',\n",
       " '  Sed cum rerum usus, et (4) mixtae iam, ac communis eorundem Indorum, et Hispanorum Reipublicae utilitas, et neccessitas, aliqua munia, sive servitia induxisse, aut etiam extorsisse videatur, quibus illi addici, et distribui coeperunt, quae isthaec, et qualia sint, et quatenus iuxta iuris regulas subsistere possint? Hoc libro sigillatim percurrere, et distinctis capitibus trutinare conabimur.\\n']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the path to our file\n",
    "bigsourcefile = 'SP_seminar/1cap_b1_TA.txt'\n",
    "# We use a variable 'input' for keeping its contents.\n",
    "input = open(bigsourcefile, encoding='utf-8').readlines()\n",
    "\n",
    "# Just for information, let's see the first 10 lines of the file.\n",
    "input[0:10]   # actually, since python starts counting with '0', we get 11 lines.\n",
    "             # and since there is no line wrapping in the source file,\n",
    "             # a line can be quite long.\n",
    "             # You can see the lines ending with a \"newline\" character \"\\n\" in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment source text<a name=\"SegmentSourceText\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, as mentioned above, we want to associate information with only passages of the text, not the text as a whole. Therefore, the text has to be segmented. The one big single file is being split into meaningful smaller chunks. What exactly constitutes a meaningful chunk -- a chapter, an article, a paragraph etc. -- cannot be known independently of the text in question and of the research questions. Therefore, a typical approach is that the scholar either splits the text manually or inserts some symbols that otherwise do not appear in the text. This is what we have here. Then, processing tools can find these symbols and split the file accordingly. For keeping things neat and orderly, the resulting files are saved in a directory of their own..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Note here and in the following that in most cases, when the program is counting, it does so beginning with zero. Which means that if we end up with 20 segments, they are going to be called segment_0.txt, segment_1,txt, ..., segment_19.txt. There is not going to be a segment bearing the number twenty, although we do have twenty segments. The first one has the number zero and the twentieth one has the number nineteen. Even for more experienced coders, this sometimes leads to mistakes, called \"off-by-one errors\".)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:12.448443Z",
     "start_time": "2017-09-12T11:48:12.398236+02:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 files written.\n"
     ]
    }
   ],
   "source": [
    "# folder for the several segment files:\n",
    "outputBase = 'SP_seminar/segment'\n",
    "\n",
    "# initialise some variables:\n",
    "at    = -1\n",
    "dest  = None                  # this later takes our destination files\n",
    "\n",
    "# Now, for every line, if it starts with our special string,\n",
    "#    do nothing with the line,\n",
    "#    but close the current and open the next destination file;\n",
    "# if it does not,\n",
    "#   append it to whatever is the current destination file\n",
    "#   (stripping leading and trailing whitespace).\n",
    "for line in input:\n",
    "    if line[0:3] == '€€€':\n",
    "        # if there is a file open, then close it\n",
    "        if dest:\n",
    "            dest.close()\n",
    "        at += 1\n",
    "        # open the next destination file for writing\n",
    "        # (It's filename is build from our outputBase variable,\n",
    "        #  the current position in the sequence of fragments,\n",
    "        #  and a \".txt\" ending)\n",
    "        dest = open(outputBase + '.' + str(at) + '.txt',\n",
    "                    encoding='utf-8',\n",
    "                    mode='w')\n",
    "    else:\n",
    "        # write the line (after it has been stripped of leading and closing whitespace)\n",
    "        dest.write(line.strip())\n",
    "\n",
    "dest.close()\n",
    "at += 1\n",
    "\n",
    "# How many segments/files do we then have?\n",
    "print(str(at) + ' files written.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read segments into a variable <a name=\"ReadSegmentsIntoVariable\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the segments just created, we rebuild our corpus, iterating through them and reading them into another variable (which now stores, technically speaking, not just one long string of characters, as the variable *input* in the first code snippet did, but a list of strings, one for each segment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:13.164623Z",
     "start_time": "2017-09-12T11:48:13.145663+02:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'SP_seminar'\n",
    "filename = 'segment.'\n",
    "suffix = '.txt'\n",
    "corpus = []           # This is our new variable. It will be populated below.\n",
    "\n",
    "for i in range(0, at):\n",
    "    with open(path + '/' + filename + str(i) + suffix, encoding='utf-8') as f:\n",
    "        corpus.append(f.read())    # Here, a new element is added to our corpus.\n",
    "                                       # Its content is read from the file 'f' opened above\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should have 20 strings in the variable *corpus* to play around with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:13.521646Z",
     "start_time": "2017-09-12T11:48:13.512877+02:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a quick impression, let's see the opening 500 characters of an arbitrary one of them; in this case, we take the first segment, i.e. the one at position '1' (remember that counting starts at 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:13.949058Z",
     "start_time": "2017-09-12T11:48:13.936996+02:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quae prioribus (1) illis libris scripsimus, quos nuper circa iustam harum Indiarum Occidentalium inquisitionem, acquisitionem, et retentionem luce donavimus, ea, ut ibidem advertimus, praestolantur, quae ad earundem gubernationem spectant. In quibus proponendis et exponendis, ut recto ordine procedatur, ab Indorum personis, earumque statu, et conditione initium capessemus; (2) quarum in omnibus iuris quaestionibus priorem, potioremque; inspectionem esse debere, optime docuit Iuris_Civilis in lib'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1][0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenising <a name=\"Tokenising\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Tokenising\" means splitting the long lines of the input into single words. Since we are dealing with plain latin, we can use the default split method which relies on spaces to identify word boundaries. (In languages like Japanese or scripts like Arabic, this is more difficult.) **Note that we do not compensate for words that are hyphenated/split across lines here!** That is something that should be catered for in the transcription itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:14.701903Z",
     "start_time": "2017-09-12T11:48:14.672851+02:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have 2987 wordforms or \"tokens\" in our corpus of 5 segments.\n"
     ]
    }
   ],
   "source": [
    "# We need a python library, because we want to use a \"regular expression\"\n",
    "import re\n",
    "\n",
    "tokenised = []     # A new variable again\n",
    "\n",
    "# Every segment, initially a long string of characters, is now split into a list of words,\n",
    "# based on non-word characters (whitespace, punctuation, parentheses and others - that's\n",
    "# what we need the regular expression library for).\n",
    "# Also, we make everything lower-case.\n",
    "for segment in corpus:\n",
    "    tokenised.append(list(filter(None, (word.lower() for word in re.split('\\W+', segment)))))\n",
    "\n",
    "print('We now have ' + str(sum(len(x) for x in tokenised)) + ' wordforms or \"tokens\" in our corpus of ' + str(len(tokenised)) + ' segments.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of *corpus*, we can use *tokenised* for our subsequent routines: a variable which, at 5 positions, contains the list of words of the corresponding segment. In order to see the difference in structure to the corpus variable above, let's have a look at (the first 50 words of) the first segment again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:15.105746Z",
     "start_time": "2017-09-12T11:48:15.094646+02:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quae', 'prioribus', '1', 'illis', 'libris', 'scripsimus', 'quos', 'nuper', 'circa', 'iustam', 'harum', 'indiarum', 'occidentalium', 'inquisitionem', 'acquisitionem', 'et', 'retentionem', 'luce', 'donavimus', 'ea', 'ut', 'ibidem', 'advertimus', 'praestolantur', 'quae', 'ad', 'earundem', 'gubernationem', 'spectant', 'in', 'quibus', 'proponendis', 'et', 'exponendis', 'ut', 'recto', 'ordine', 'procedatur', 'ab', 'indorum', 'personis', 'earumque', 'statu', 'et', 'conditione', 'initium', 'capessemus', '2', 'quarum']\n"
     ]
    }
   ],
   "source": [
    "print(tokenised[1][0:49])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already, we can have a first go at finding the most frequent words for a segment. (For this we use a simple library of functions that we import by the name of 'collections'.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:15.501886Z",
     "start_time": "2017-09-12T11:48:15.481384+02:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('et', 61), ('in', 46), ('cum', 13), ('quae', 12), ('ut', 10), ('quod', 9), ('vel', 9), ('aliis', 8), ('non', 7), ('ad', 7)]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "counter = collections.Counter(tokenised[3])  # Again, consider the fourth segment\n",
    "print(counter.most_common(10))               # Making a counter 'object' of our segment,\n",
    "                                             # this now has a 'method' calles most_common,\n",
    "                                             # offering us the object's most common elements.\n",
    "                                             # More 'methods' can be found in the documentation:\n",
    "                                             # https://docs.python.org/3/library/collections.html#collections.Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming / Lemmatising <a name=\"StemmingLemmatising\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, since we prefer to count different word *forms* as one and the same \"*lemma*\", we have to do a step called \"lemmatisation\". In languages that are not strongly inflected, like English, one can get away with \"stemming\", i.e. just eliminating the ending of words: \"wish\", \"wished\", \"wishing\", \"wishes\" all can count as instances of \"wish\\*\". With Latin this is not so easy: we want to count occurrences of \"legum\", \"leges\", \"lex\" as one and the same word, but if we truncate after \"le\", we get too many hits that have nothing to do with lex at all. There are a couple of \"lemmatising\" tools available, although with classical languages (or even early modern ones), it's a bit more difficult. Anyway, we do our own, using a dictionary approach..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to have a dictionary which associates all known word forms to their lemma. This can also help us with historical orthography. Suppose from some other context, we have a file \"[wordforms-lat-full.txt](SP_seminar/wordforms-lat-full.txt)\" at our disposal in the folder \"SP_seminar\". Its contents looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:17.990249Z",
     "start_time": "2017-09-12T11:48:17.970041+02:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aër > aër\n",
      "aëre > aër\n",
      "aërem > aër\n",
      "aëri > aër\n",
      "aëris > aër\n",
      "a > a\n",
      "ab\n"
     ]
    }
   ],
   "source": [
    "wordfile_path = 'SP_seminar/wordforms-lat-full.txt'\n",
    "wordfile = open(wordfile_path, encoding='utf-8')\n",
    "\n",
    "print(wordfile.read()[:64])     # in such from-to addresses, one can just skip the zero\n",
    "wordfile.close;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we again build a dictionary of key-value pairs associating all the lemmata (\"values\") with their wordforms (\"keys\"). And afterwards, we can quickly look up the value under a given key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:18.431868Z",
     "start_time": "2017-09-12T11:48:18.398703+02:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2131207 wordforms known to the system.\n"
     ]
    }
   ],
   "source": [
    "lemma    = {}    # we build a so-called dictionary for the lookups\n",
    "tempdict = []\n",
    "\n",
    "# open the wordfile (defined above) for reading\n",
    "wordfile = open(wordfile_path, encoding='utf-8')\n",
    "\n",
    "for line in wordfile.readlines():\n",
    "    tempdict.append(tuple(line.split('>'))) # we split each line by \">\" and append a tuple to a\n",
    "                                            # temporary list.\n",
    "\n",
    "lemma = {k.strip(): v.strip() for k, v in tempdict} # for every tuple in the list,\n",
    "                                                    # we strip whitespace and make a key-value\n",
    "                                                    # pair, appending it to our \"lemma\" dictionary\n",
    "wordfile.close\n",
    "print(str(len(lemma)) + ' wordforms known to the system.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, a quick test: Let's see with which \"lemma\"/basic word the particular wordform \"ciuicior\" is associated, or, in other words, what *value* our lemma variable returns when we query for the *key* \"fidem\" (Accusative for the Nominative \"fides\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:18.878222Z",
     "start_time": "2017-09-12T11:48:18.858115+02:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fides'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma['fidem']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this dictionary to build a new list of words, where only lemmatised forms occur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:19.417240Z",
     "start_time": "2017-09-12T11:48:19.404334+02:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For each segment, and for each word in it, add the lemma to our new \"lemmatised\"\n",
    "# list, or, if we cannot find a lemma, add the actual word from from the tokenised list.\n",
    "lemmatised = [[lemma[word] if word in lemma else word for word in segment]\n",
    "              for segment in tokenised]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's see the first 50 words from the first segment, and compare them with the \"tokenised\" variant above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:19.865811Z",
     "start_time": "2017-09-12T11:48:19.853901+02:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qui', 'prior', '1', 'ille', 'liber', 'scribo', 'qui', 'nuper', 'circa', 'iustus', 'hic', 'india', 'occidentalis', 'inquisitio', 'acquisitio', 'et', 'retentio', 'luceo', 'dono', 'ea', 'ut', 'ibidem', 'adverto', 'praestolor', 'qui', 'ad', 'idem', 'gubernatio', 'specto', 'in', 'qui', 'propono', 'et', 'expono', 'ut', 'recto', 'ordo', 'procedo', 'a', 'indorum', 'persona', 'earumque', 'sisto', 'et', 'condicio', 'initium', 'capesso', '2', 'qui']\n"
     ]
    }
   ],
   "source": [
    "print(lemmatised[1][:49])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the original text is lost now from the data that we are currently working with (unless we add another dimension to our lemmatised variable which can keep the original word form). But let us see if something in the 10 most frequent words has changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('qui', 5), ('et', 3), ('in', 3), ('prior', 2), ('ut', 2), ('1', 1), ('ille', 1), ('liber', 1), ('scribo', 1), ('nuper', 1)]\n"
     ]
    }
   ],
   "source": [
    "counter = collections.Counter(lemmatised[1])  # Again, consider the fourth segment\n",
    "print(counter.most_common(10))               # Making a counter 'object' of our segment,\n",
    "                                             # this now has a 'method' calles most_common,\n",
    "                                             # offering us the object's most common elements.\n",
    "                                             # More 'methods' can be found in the documentation:\n",
    "                                             # https://docs.python.org/3/library/collections.html#collections.Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate Stopwords <a name=\"EliminateStopwords\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably \"et\", \"in\", \"de\", \"qui\", \"ad\", \"sum/esse\", \"non/nolo\" and many of the most frequent words are not really very telling words. They are what one calls *stopwords*, and we have another [list of such words](SP_seminar/stopwords-lat.txt) that we would rather want to ignore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:21.725760Z",
     "start_time": "2017-09-12T11:48:21.710968+02:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392 stopwords known to the system, e.g.: ['a', 'ab', 'ac', 'ad', 'adhic', 'adhuc', 'ae', 'ait', 'ali', 'alii', 'aliis', 'alio', 'aliqua', 'aliqui', 'aliquid', 'aliquis', 'aliquo', 'am', 'an', 'ante', 'apud', 'ar', 'at', 'atque', 'au', 'aut', 'autem', 'bus', 'c', 'ca', 'cap', 'ceptum', 'circa', 'co', 'con', 'cui', 'cum', 'cur', 'cùm', 'd', 'da', 'de', 'deinde', 'detur', 'di', 'diu', 'do', 'dum', 'e', 'ea', 'eadem', 'earumque', 'ec', 'eccle', 'ego', 'ei', 'eis', 'eius', 'el', 'em', 'en', 'enim', 'eo', 'eorundem', 'eos', 'er', 'erat', 'ergo', 'erit', 'es', 'esse', 'essent', 'esset', 'est', 'et']\n"
     ]
    }
   ],
   "source": [
    "stopwords_path = 'SP_seminar/stopwords-lat.txt'\n",
    "stopwords = open(stopwords_path, encoding='utf-8').read().splitlines()\n",
    "\n",
    "print(str(len(stopwords)) + ' stopwords known to the system, e.g.: ' + str(stopwords[95:170]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and suppress the stopwords in the segments (and see what the \"reduced\" first segment gives)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:22.285616Z",
     "start_time": "2017-09-12T11:48:22.186486+02:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prior', 'liber', 'scribo', 'nuper', 'iustus', 'india', 'occidentalis', 'inquisitio', 'acquisitio', 'retentio', 'luceo', 'dono', 'adverto', 'praestolor', 'gubernatio', 'specto', 'propono', 'expono', 'recto', 'ordo', 'procedo', 'indorum', 'persona', 'sisto', 'condicio', 'initium', 'capesso', 'ius', 'quaestio', 'prior', 'potioremque', 'inspectio', 'debeo', 'bonus', 'doceo', 'iuris_civilis', 'liber_2_digesta_de_statu_hominum_lex_si_quaeremus', 'liber_6_digesta_de_testamento_lex_quidam_referunt', 'liber_14_decretus_de_iure_codicilli_paragraphus_ultimo', 'institutiones_de_iure_naturalis_lex_2_paragraphus_post_originem', 'de_origine_iure']\n"
     ]
    }
   ],
   "source": [
    "# For each segment, and for each word in it,\n",
    "# add it to a new list called \"stopped\",\n",
    "# but only if it is not listed in the list of stopwords.\n",
    "stopped = [[item for item in lemmatised_segment if item not in stopwords and item[1] != \"Њ\"] \\\n",
    "           for lemmatised_segment in lemmatised]\n",
    "print(stopped[1][:49])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can already create a kind of first \"profile\" of, in this case, our four segments (which account for the whole chapter 1, book 1, T.A. - minus the title segment) listing the most frequent words in each of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('prior', 2), ('liber', 1), ('scribo', 1), ('nuper', 1), ('iustus', 1), ('india', 1), ('occidentalis', 1), ('inquisitio', 1), ('acquisitio', 1), ('retentio', 1), ('luceo', 1), ('dono', 1), ('adverto', 1), ('praestolor', 1), ('gubernatio', 1), ('specto', 1), ('propono', 1), ('expono', 1), ('recto', 1), ('ordo', 1), ('procedo', 1), ('indorum', 1), ('persona', 1), ('sisto', 1), ('condicio', 1), ('initium', 1), ('capesso', 1), ('ius', 1), ('quaestio', 1), ('potioremque', 1)]\n"
     ]
    }
   ],
   "source": [
    "counter = collections.Counter(stopped[1])  # Again, consider the fourth segment\n",
    "print(counter.most_common(30))               # Making a counter 'object' of our segment,\n",
    "                                             # this now has a 'method' calles most_common,\n",
    "                                             # offering us the object's most common elements.\n",
    "                                             # More 'methods' can be found in the documentation:\n",
    "                                             # https://docs.python.org/3/library/collections.html#collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('servitium', 12), ('alea', 10), ('personalis', 9), ('liber', 8), ('indo', 8), ('tribuo', 8), ('anno', 7), ('indos', 5), ('schedula', 5), ('certus', 5)]\n"
     ]
    }
   ],
   "source": [
    "counter = collections.Counter(stopped[2])  # Again, consider the fourth segment\n",
    "print(counter.most_common(10))               # Making a counter 'object' of our segment,\n",
    "                                             # this now has a 'method' calles most_common,\n",
    "                                             # offering us the object's most common elements.\n",
    "                                             # More 'methods' can be found in the documentation:\n",
    "                                             # https://docs.python.org/3/library/collections.html#collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('alea', 13), ('servitium', 8), ('schedula', 5), ('maga', 5), ('opera', 5), ('dico', 5), ('curo', 4), ('princeps', 4), ('multus', 4), ('sibus', 4)]\n"
     ]
    }
   ],
   "source": [
    "counter = collections.Counter(stopped[3])  # Again, consider the fourth segment\n",
    "print(counter.most_common(10))               # Making a counter 'object' of our segment,\n",
    "                                             # this now has a 'method' calles most_common,\n",
    "                                             # offering us the object's most common elements.\n",
    "                                             # More 'methods' can be found in the documentation:\n",
    "                                             # https://docs.python.org/3/library/collections.html#collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dico', 13), ('tribuo', 7), ('servitium', 6), ('indos', 5), ('lex', 5), ('facio', 4), ('personalis', 4), ('indo', 4), ('soleo', 4), ('alea', 4)]\n"
     ]
    }
   ],
   "source": [
    "counter = collections.Counter(stopped[4])  # Again, consider the fourth segment\n",
    "print(counter.most_common(10))               # Making a counter 'object' of our segment,\n",
    "                                             # this now has a 'method' calles most_common,\n",
    "                                             # offering us the object's most common elements.\n",
    "                                             # More 'methods' can be found in the documentation:\n",
    "                                             # https://docs.python.org/3/library/collections.html#collections.Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alertbox alert-success\">So far our initial analyses, then. There are several ways in which we can continue now. We see that there are still word (like 'damnatione', tributorum' in the first or 'statuunt' in the second segment) that are not covered by our lemmatisation process. Also, abbreviations (like 'iur' in the second segment) could be expanded either in the transcription or by adding an appropriate line in our list of lemmata. Words like 'dom' in the fifth segment could maybe be added to the list of stopwords? Anyway, more need for review of these two lists (lemmata/stopwords) is explained below and that is something that should definitely be done - after all, they were taken from the context of quite another project and a scholar should control closely  what is being suppressed and what is being replaced in the text under hand.</div>\n",
    "\n",
    "<div class=\"alert alertbox alert-success\">But we could also do more sophisticated things with the list. We could e.g. use either our lemma list or our stopwords list to filter out certain words, like all non-substantives. Or we could reduce all mentions of a certain name or literary work to a specific form (that would be easily recognizable in all the places).</div>\n",
    "\n",
    "However, we can already observe that meaningful words like \"indios/indis\" are maybe not so helpful in characterising individual passages of this work, since they occur all over the place. After all, the work is called \"De Indiarum Iure\" and deals with various questions all related to indigenous people. Also, we would like to give some weight to the fact that a passage may consist of all stopwords and perhaps one or two substantial words, whereas another might be full of substantial words and few stopwords only (think e.g. of an abstract or an opening chapter describing the rest of the work). Or, since we have text segments of varying length, we would like our figures to reflect the fact that a tenfold occurrence in a very short passage may be more significant than a tenfold occurrence in a very, very, very long passage.\n",
    "\n",
    "These phenomena are treated with more mathematical tools, so let's say that our preparatory work is done ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterise passages: TF/IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described, we are now going to delve a wee bit deeper into mathematics in order to get more precise characterizations of our text segments. The approach we are going to use is called \"TF/IDF\" and is a simple, yet powerful method that is very popular in text mining and search engine discussions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. [Build vocabulary](#BuildVocabulary)\n",
    "  2. [Calculate Terms' Text Frequencies (TF)](#CalculateTF) \n",
    "  3. [Normalise TF](#NormaliseTF)\n",
    "  4. [Inverse Document Frequencies (IDF) and TF-IDF](#CalculateTFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocabulary <a name=\"BuildVocabulary\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since maths works best with numbers, let's first of all build a list of all the words (in their basic form) that occur anywhere in the text, and give each one of those words an ID (say, the position of its first occurrence in the work):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:27.377351Z",
     "start_time": "2017-09-12T11:48:26.745263+02:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1144 distinct words in the corpus:\n",
      "['1542', '1549', '1555', '1568', '1581', '1595', '1601', '1601_die_24_november_vallisoleti', '1604', '1617', '1620', '1_tomus_controversia_liber_3_de_laici_capitus_7', '1_tomus_impresso_pagina_320', '27_capitus', '2_var_capitum_14_numerus_28', '43', '4_tomus_impressus_pagina_292', '4_tomus_pagina_301', '8_december_anno_1610', 'aboleo', 'absolvo', 'absque', 'abutor', 'accipio', 'acquisitio', 'actio', 'actum', 'addico', 'additio', 'addo', 'adduco', 'administratio', 'admodum', 'adscriptitiis', 'adversus', 'adverto', 'aedifico', 'aequum', 'aestimo', 'aetas', 'afflictus', 'affligo', 'africanos', 'ager', 'agero', 'ago', 'agricolis_et_censitis_liber_11', 'alea', 'alibi', 'aliquot', 'alium', 'alius', 'allego', 'alter', 'ambigo', 'anno', 'annua', 'annus', 'antiqua', 'antiquus', 'aperio', 'apostolicus', 'appareo', 'appello', 'applico', 'apud_dominus_laurentius_19_october_anno_1591', 'aranjuecii_26_maii_anno_1609', 'arceo', 'archidiaconus', 'ardens', 'argumentum', 'ascribo', 'asservio', 'assigno', 'atrox', 'auctoritas', 'auctus', 'audio', 'auditor', 'aufero', 'auris', 'authoritate_de_collatoribus_parraphus_ad_hoc_iubemus', 'authoritate_de_nulli_iudicium_parrapho_cuius', 'authoritate_ut_iudices_sine_quoquo_suffragio_in_principis', 'avaritia', 'baro', 'bellum', 'bonum', 'bonus', 'bulla', 'cado', 'cancellarius', 'capesso', 'capitatio', 'capitum_15', 'capitum_17_pagina_342', 'capitum_2', 'capitum_24_praet_verbum_titulo', 'capitum_bonae', 'capitum_fin_de_consuetudine']\n"
     ]
    }
   ],
   "source": [
    "# We can use a library function for this\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Since the library function can do all of the above (splitting, tokenising, lemmatising),\n",
    "# and since it is providing hooks for us to feed our own tokenising, lemmatising and stopwords\n",
    "# resources or functions to it,\n",
    "# we use it and work on our rather raw \"corpus\" variable from way above again.\n",
    "\n",
    "# So first we build a tokenising and lemmatising function to work as an input filter\n",
    "# to the CountVectorizer function\n",
    "def ourLemmatiser(str_input):\n",
    "    wordforms = re.split('\\W+', str_input)\n",
    "    return [lemma[wordform].lower().strip() if wordform in lemma else wordform.lower().strip() for wordform in wordforms ]\n",
    "\n",
    "# Then we initialize the CountVectorizer function to use our stopwords and lemmatising fct.\n",
    "count_vectorizer = CountVectorizer(tokenizer=ourLemmatiser, stop_words=stopwords)\n",
    "\n",
    "# Finally, we feed our corpus to the function, building a new \"vocab\" object\n",
    "vocab = count_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Print some results\n",
    "print(str(len(count_vectorizer.get_feature_names())) + ' distinct words in the corpus:')\n",
    "print(count_vectorizer.get_feature_names()[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how our corpus of four thousand \"tokens\" actually contains only one and a half thousand different words (plus stopwords, but these are at maximum 384). And, in contrast to simpler numbers that have been filtered out by our stopwords filter, I have left years like \"1610\" in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Terms' Text Frequencies (TF) <a name=\"CalculateTF\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, our \"vocab\" object contains more than just all the unique words in our corpus. Let's get some information about it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:28.691789Z",
     "start_time": "2017-09-12T11:48:28.677888+02:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x1144 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1443 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is actually a table with 20 rows (the number of our segments) and 1.672 columns (the number of unique words in the corpus). So what we do have is a table where for each segment the amount of occurrences of every \"possible\" (in the sense of used somewhere in the corpus) word is listed.\n",
    "\n",
    "*(\"Sparse\" means that the majority of fields is zero. And 2.142 fields are populated, which is more than the number of unique words in the corpus (1.672, see above) - that's obviously because some words occur in multiple segments = rows. Not much of a surprise, actually.)*\n",
    "\n",
    "Here is the whole table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:29.480646Z",
     "start_time": "2017-09-12T11:48:29.396064+02:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(vocab.toarray(), columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of this table is a kind of fingerprint of a segment: We don't know the order of words in the segment - for us, it is just a \"*bag of words*\" -, but we know which words occur in the segment and how often they do. But as of now, it is a rather bad fingerprint, because how significant a certain number of occurences of a word in a segment is depends on the actual length of the segment. Ignorant as we are (per assumption) of the role and meaning of those words, still, if a word occurs twice in a short paragraph, that should *prima facie* count as more characteristic of the paragraph than if it occurs twice in a multi-volume work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise TF <a name=\"NormaliseTF\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reflect this if we divide the number of occurrences of a word by the number of tokens in the segment. Obviously the number will then be quite small - but what counts is the relations between the cells and we can account for scaling and normalizing later...\n",
    "\n",
    "We're almost there and we are switching from the CountVectorizer function to another one, that does the division just mentioned and will do more later on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:31.397897Z",
     "start_time": "2017-09-12T11:48:31.265380+02:00"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x1144 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1443 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the library's function\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords, use_idf=False, tokenizer=ourLemmatiser, norm='l1')\n",
    "\n",
    "# Finally, we feed our corpus to the function to build a new \"tf_matrix\" object\n",
    "tf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Print some results\n",
    "# pd.DataFrame(tf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "tf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have seen above that \"indis\" is occurring in all of the segments, because, as the title indicates, the whole work is about issues related to the Indies and to indigenous people. When we want to characterize a segment by referring to some of its words, is there a way to weigh down words like \"indis\" a little bit? Not filter them out completely, as we do with stopwords, but give them just a little less weight than words not appearing all over the place? Yes there is..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Inverse Document Frequencies (IDF) and TF-IDF <a name=\"CalculateTFIDF\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a measure called \"text frequency / (inverse) document frequency\" that combines a *local* measure (how frequently a word appears in a segment, in comparison to the other words appearing in the same segment, viz. the table above), with a *global* measure (how frequently the word appears throughout the whole corpus). Roughly speaking, we have to add to the table above a new, global, element: the number of *documents* the term appears in divided through the number of *all documents* in the corpus - or, rather, the other way round (that's why it is the \"*inverse*\" document frequency): the number of documents in the corpus divided by the number of documents the current term occurs in. *(As with our local measure above, there is also some normalization, i.e. compensation for different lengths of documents and attenuation of high values, going on by using a logarithm on the quotient.)*\n",
    "\n",
    "When you multiply the term frequency (from above) with this inverse document frequeny, you have a formula which \"rewards\" frequent occurrences in one segment and rare occurrences over the whole corpus. (For more of the mathematical background, see [this tutorial](http://blog.christianperone.com/2011/10/machine-learning-text-feature-extraction-tf-idf-part-ii/).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we do not have to implement all the counting, division and logarithm ourselves but can rely on SciKit-learn's TfidfVectorizer function to generate a matrix of our corpus in just a few lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:33.988013Z",
     "start_time": "2017-09-12T11:48:33.835734+02:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x1144 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1443 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the library's function\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords, use_idf=True, tokenizer=ourLemmatiser, norm='l2')\n",
    "\n",
    "# Finally, we feed our corpus to the function to build a new \"tfidf_matrix\" object\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Print some results\n",
    "# tfidf_matrix_frame = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "# tfidf_matrix_frame\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print a more qualified \"top 10\" words for each segment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:34.824830Z",
     "start_time": "2017-09-12T11:48:34.566011+02:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert your matrix to an array to loop over it\n",
    "mx_array = tfidf_matrix.toarray()\n",
    "\n",
    "# get your feature names\n",
    "fn = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# pos = 0\n",
    "# for l in mx_array:\n",
    "#    print(' ')\n",
    "#    print(' Most significant words segment ' + str(pos) + ':')\n",
    "#    print(pd.DataFrame.rename(pd.DataFrame.from_dict([(fn[x], l[x]) for x in (l*-1).argsort()][:20]), columns={0:'lemma',1:'tf/idf value'}))\n",
    "#    pos += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alertbox alert-success\">You can see that, in the fourth segment, pensum and tributum have moved up while indis has fallen from the first to the third place. But in other segments you can also see that abbreviations like \"fol\", \"gl\" or \"hom\" still are a major nuisance, and so are spanish passages. It would surely help to improve our stopwords and lemma lists.</div>\n",
    "\n",
    "<div class=\"alert alertbox alert-success\">Of course, having more text would also help: The *idf* can kick in only when there are many documents... Also, you could play around with the segmentation. Make fewer but bigger segments or smaller ones...</div>\n",
    "\n",
    "<div class=\"alert alertbox alert-success\">And you can notice that in many segments, the lemmata at around rank 5 have the exact same value. Most certainly that's because they only occur one single time in the segment. (That those values differ from segment to segment has to do with the relation of the segment to the corpus as a whole.) And when four our fourteen of those words occur only once anyway, we should really not think that there is a meaningful sorting order between them (or that there is a good reason the 8th one is in the top ten list and the thirteenth one isn't). But in those areas where there _is_ variation in the tf/idf values, that is indeed telling.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the way that they have been encoded in our sample texts, we can also observe some references to other literature by the underscore (e.g. \"de_oper\", \"de_iur\", \"et_cur\" etc.), which makes you wonder if it would be worthwile marking all the references in some way so that we could either concentrate on them or filter them out altogether. But other than that, it's in fact almost meaningful. Apart from making such lists, what can we do with this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Space Model of the text <a name=\"#VectorSpaceModel\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us recapitulate in more general terms what we have done so far, since a good part of it is extensible and applicable to many other methods: We have used a representation of each \"document\" (in our case, all those \"documents\" have been segments of one and the same text) as a series of values that indicated the document's relevance in particular \"dimensions\".\n",
    "\n",
    "For example, the various values in the \"alea dimension\" indicate how characteristic this word, \"alea\", is for the present document. (By hypothesis, this also works the other way round, as an indication of which documents are the most relevant ones in matters of \"alea\". In fact, this is how search engines work.)\n",
    "\n",
    "Many words did not occur at all in most of the documents and the series of values (matrix rows) contained many zeroes. Other words were stopwords which we would not want to affect our documents' scores - they did not yield a salient \"dimension\" and were dropped from the series of values (matrix columns). The values work independently and can be combined (when a document is relevant in one *and* in another dimension).\n",
    "\n",
    "Each document is thus characterised by a so-called \"vector\" (a series of independent, combinable values) and is mapped in a \"space\" constituted by the dimensions of those vectors (matrix columns, series of values). In our case the dimensions have been derived from the corpus's vocabulary. Hence, the representation of all the documents is called their vector space model. You can really think of it as similar to a three-dimensional space: *Document A goes quite some way in the x-direction, it goes not at all in the y-direction and it goes just a little bit in the z-direction. Document B goes quite some way, perhaps even further than A did, in both the y- and z- directions, but only a wee bit in the y-direction. Etc. etc. Only with many many more independent dimensions instead of just the three spatial dimensions we are used to.*\n",
    "\n",
    "The following sections are will discuss ways of manipulating the vector space -- using alternative or additional dimensions -- and also ways of leveraging the VSM representation of our text to make various analyses..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [Word clouds](#WordClouds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending the dimensions <a name=\"AddDimensions\"/>\n",
    "\n",
    "Of course, there is no reason why the dimensions should be restricted to or identical with the vocabulary (or the occurring n-grams, for that matter). In fact, in the examples above, we have dropped some of the words already by using our list of stopwords. <font color=\"green\">**We could also add other dimensions that are of interest for our current research question. We could add a dimension for the year in which the texts have been written, for their citing a certain author, or merely for their position in the encompassing work...**</font>\n",
    "\n",
    "Since in our examples, the position is represented in the \"row number\" and counting citations of a particular author require some more normalisations (e.g. with the lemmatisation dictionary above), let's add a dimension for the length of the respective segment (in characters) and another one for the number of occurrences of \"\\_\" (in our sample transcriptions, this character had been used to mark citations, although admittedly not all of them), just so you get the idea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:39.742267Z",
     "start_time": "2017-09-12T11:48:39.694938+02:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"Original matrix of tf/idf values (rightmost columns):\")\n",
    "# tfidf_matrix_frame.iloc[ :, -5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:39.814025Z",
     "start_time": "2017-09-12T11:48:39.751031+02:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = []\n",
    "for i in range(0, len(corpus)):\n",
    "    length.append(len(tokenised[i]))\n",
    "\n",
    "citnum = []\n",
    "for i in range(0, len(corpus)):\n",
    "    citnum.append(corpus[i].count('Ж'))\n",
    "\n",
    "# print(\"New matrix extended with segment length and number of occurrences of 'Ж':\")\n",
    "# new_matrix = tfidf_matrix_frame.assign(seg_length = length).assign(cit_count = citnum)\n",
    "# new_matrix.iloc[ :, -6:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that the segment with most occurrences of \"\\_\" (taken with a grain of salt, that's likely the segment with most citations), is not a particularly long one. If we had systematic markup of citations or author names in our transcription, we could be more certain or add even more columns/\"dimensions\" to our table.\n",
    "\n",
    "If you bear with me for a final example, here is adding the labels that you could see in our initial one \"big source file\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-12T09:48:40.727778Z",
     "start_time": "2017-09-12T11:48:40.677687+02:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input should still have a handle on our source file.\n",
    "\n",
    "label = []\n",
    "# Now, for every line, revisit the special string and extract just the lines marked by it\n",
    "for line in input:\n",
    "    if line[0:3] == '€€€':\n",
    "        label.append(line[6:].strip())\n",
    "\n",
    "# How many segments/files do we then have?\n",
    "# print(str(len(label)) + ' labels read.')\n",
    "# print(\"New matrix extended with segment length, number of occurrences of '_' and label:\")\n",
    "# yet_another_matrix = new_matrix.assign(seg_length = length).assign(label = label)\n",
    "# yet_another_matrix.iloc[ :, -6:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Clouds <a name=\"WordClouds\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a library that takes word frequencies like above, calculates corresponding relative sizes of words and creates nice wordcloud images for our sections (again, taking the fourth segment as an example) like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-12T09:48:42.357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAADKCAYAAABDsfw/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6d11f5828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We make tuples of (lemma, tf/idf score) for one of our segments\n",
    "# But we have to convert our tf/idf weights to pseudo-frequencies (i.e. integer numbers)\n",
    "frq = [ int(round(x * 100000, 0)) for x in mx_array[1]]\n",
    "freq = dict(zip(fn, frq))\n",
    "\n",
    "wc = WordCloud(background_color=None, mode=\"RGBA\", max_font_size=40, min_font_size=10, \\\n",
    "                       max_words=60, relative_scaling=0.8).fit_words(freq)\n",
    "\n",
    "# Now show/plot the wordcloud\n",
    "plt.figure()\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have a nicer overview over the many segments than is possible in this notebook, let's create a new html file listing some of the characteristics that we have found so far..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-12T09:48:43.347Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputDir = \"SP_seminar\"\n",
    "htmlfile = open(outputDir + '/Overview.html', encoding='utf-8', mode='w')\n",
    "\n",
    "# Write the html header and the opening of a layout table\n",
    "htmlfile.write(\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>Section Characteristics</title>\n",
    "        <meta charset=\"utf-8\"/>\n",
    "    </head>\n",
    "    <body>\n",
    "        <table>\n",
    "\"\"\")\n",
    "\n",
    "a = [[]]\n",
    "a.clear()\n",
    "dicts = []\n",
    "w = []\n",
    "\n",
    "# For each segment, create a wordcloud and write it along with label and\n",
    "# other information into a new row of the html table\n",
    "for i in range(0, len(mx_array)):\n",
    "    # this is like above in the single-segment example...\n",
    "    a.append([ int(round(x * 100000, 0)) for x in mx_array[i]])\n",
    "    dicts.append(dict(zip(fn, a[i])))\n",
    "    w.append(WordCloud(background_color=None, mode=\"RGBA\", \\\n",
    "                       max_font_size=40, min_font_size=10, \\\n",
    "                       max_words=60, relative_scaling=0.8).fit_words(dicts[i]))\n",
    "    # We write the wordcloud image to a file\n",
    "    w[i].to_file(outputDir + '/wc_' + str(i) + '.png')\n",
    "    # Finally we write the column row\n",
    "    htmlfile.write(\"\"\"\n",
    "            <tr>\n",
    "                <td>\n",
    "                    <head>Section {a}: <b>{b}</b></head><br/>\n",
    "                    <img src=\"./wc_{a}.png\"/><br/>\n",
    "                    <small><i>length: {c} words</i></small>\n",
    "                </td>\n",
    "            </tr>\n",
    "            <tr><td>&nbsp;</td></tr>\n",
    "\"\"\".format(a = str(i), b = label[i], c = len(tokenised[i])))\n",
    "\n",
    "# And then we write the end of the html file.\n",
    "htmlfile.write(\"\"\"\n",
    "        </table>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\")\n",
    "htmlfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should have created a nice html file which we can open [here](./SP_seminar/Overview.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with several languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us prepare a second text, this time in Spanish, and see how they compare..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-12T09:48:52.145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 files written.\n",
      "5 files read.\n",
      "5 labels found.\n",
      "614725 spanish wordforms known to the system.\n",
      "744 spanish stopwords known to the system.\n",
      "['', 'ϫ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17']\n",
      " \n",
      "Significant words in the spanish text:\n",
      " \n",
      " Most significant words in the 1. segment:\n",
      "['totalmente', 'capitvlo', 'español', 'tributar', 'particular', 'casa', 'llamar', 'servicio', 'cosa', 'indio']\n",
      " \n",
      " Most significant words in the 2. segment:\n",
      "['forzar', 'latir', 'юego', 'жaristoteles', 'compeler', 'sacar', 'hombre', 'servicio', 'et', 'ministerio']\n",
      " \n",
      " Most significant words in the 3. segment:\n",
      "['servicio', 'indio', 'mesmo', 'año', 'personal', 'pagar', 'de+el', 'tasar', 'provincia', 'proveer']\n",
      " \n",
      " Most significant words in the 4. segment:\n",
      "['cedula', 'de+el', 'año', 'a el', 'et', 'жmontesclaro', 'término', 'acordar', 'marcar', 'señor']\n",
      " \n",
      " Most significant words in the 5. segment:\n",
      "['dictar', 'señalar', 'et', 'apud', 'юme', 'жacosta', 'tributar', 'supra', 'prescripción', 'жcovarrubias']\n"
     ]
    }
   ],
   "source": [
    "bigspanishfile = 'SP_seminar/2cap_b2_PI.txt'\n",
    "spInput = open(bigspanishfile, encoding='utf-8').readlines()\n",
    "\n",
    "spAt    = -1\n",
    "spDest  = None\n",
    "\n",
    "for line in spInput:\n",
    "    if line[0:3] == '€€€':\n",
    "        if spDest:\n",
    "            spDest.close()\n",
    "        spAt += 1\n",
    "        spDest = open(outputBase + '.' + str(spAt) +\n",
    "                    '.spanish.txt', encoding='utf-8', mode='w')\n",
    "    else:\n",
    "        spDest.write(line.strip())\n",
    "\n",
    "spAt += 1\n",
    "spDest.close()\n",
    "print(str(spAt) + ' files written.')\n",
    "\n",
    "spSuffix = '.spanish.txt'\n",
    "spCorpus = []\n",
    "for i in range(0, spAt):\n",
    "    try:\n",
    "        with open(path + '/' + filename + str(i) + spSuffix, encoding='utf-8') as f:\n",
    "            spCorpus.append(f.read())\n",
    "            f.close()\n",
    "    except IOError as exc:\n",
    "        if exc.errno != errno.EISDIR:  # Do not fail if a directory is found, just ignore it.\n",
    "            raise                      # Propagate other kinds of IOError.\n",
    "\n",
    "print(str(len(spCorpus)) + ' files read.')\n",
    "\n",
    "# Labels\n",
    "spLabel = []\n",
    "i = 0\n",
    "for spLine in spInput:\n",
    "    if spLine[0:3] == '€€€':\n",
    "        spLabel.append(spLine[6:].strip())\n",
    "        i =+ 1\n",
    "print(str(len(spLabel)) + ' labels found.')\n",
    "\n",
    "# Tokens\n",
    "spTokenised = []\n",
    "for spSegment in spCorpus:\n",
    "    spTokenised.append(list(filter(None, (spWord.lower()\n",
    "                                        for spWord in re.split('\\W+', spSegment)))))\n",
    "\n",
    "# Lemmata\n",
    "spLemma    = {}\n",
    "spTempdict = []\n",
    "spWordfile_path = 'SP_seminar/wordforms-es.txt'\n",
    "spWordfile = open(spWordfile_path, encoding='utf-8')\n",
    "\n",
    "for spLine in spWordfile.readlines():\n",
    "    spTempdict.append(tuple(spLine.split('>')))\n",
    "\n",
    "spLemma = {k.strip(): v.strip() for k, v in spTempdict}\n",
    "spWordfile.close\n",
    "print(str(len(spLemma)) + ' spanish wordforms known to the system.')\n",
    "\n",
    "# Stopwords\n",
    "spStopwords_path = 'SP_seminar/stopwords-es.txt'\n",
    "spStopwords = open(spStopwords_path, encoding='utf-8').read().splitlines()\n",
    "print(str(len(spStopwords)) + ' spanish stopwords known to the system.')\n",
    "print(spStopwords[:20])\n",
    "print(' ')\n",
    "print('Significant words in the spanish text:')\n",
    "\n",
    "# tokenising and lemmatising function\n",
    "def spOurLemmatiser(str_input):\n",
    "    spWordforms = re.split('\\W+', str_input)\n",
    "    return [spLemma[spWordform].lower() if spWordform in spLemma else spWordform.lower() for spWordform in spWordforms ]\n",
    "\n",
    "spTfidf_vectorizer = TfidfVectorizer(stop_words=spStopwords, use_idf=True, tokenizer=spOurLemmatiser, norm='l2')\n",
    "spTfidf_matrix = spTfidf_vectorizer.fit_transform(spCorpus)\n",
    "\n",
    "spMx_array = spTfidf_matrix.toarray()\n",
    "spFn = spTfidf_vectorizer.get_feature_names()\n",
    "\n",
    "pos = 1\n",
    "for l in spMx_array:\n",
    "    print(' ')\n",
    "    print(' Most significant words in the ' + str(pos) + '. segment:')\n",
    "#    print(pd.DataFrame.rename(pd.DataFrame.from_dict([(spFn[x], l[x]) for x in (l*-1).argsort()][:10]), columns={0:'lemma',1:'tf/idf value'}))\n",
    "    print([spFn[x] for x in (l*-1).argsort()][:10])\n",
    "    pos += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alertbox alert-success\">Our spanish wordfiles ([lemmata list](Solorzano/wordforms-es.txt) and [stopwords list](Solorzano/stopwords-es.txt)) are quite large and generous - they spare us some work of resolving quite a lot of abbreviations. However, since they are actually originating from a completely different project, it is very unlikely, that this goes without mistakes. Also some lemmata (like \"de+el\" in the eighth segment) are not really such. So we need to clean our wordlist and adapt it to the current text material urgently!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now imagine how we would bring the two documents together in a vector space. We would generate dimensions for all the words of our spanish vocabulary and would end up with a common space of roughly twice as many dimensions as before - and the latin work would be only in the first half of the dimensions and the spanish work only in the second half. The respective other half would be populated with only zeroes. So in effect, we would not really have a *common* space or something on the basis of which we could compare the two works. :-("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What might be an interesting perspective, however - since in this case, the second text is a translation of the first one - is a parallel, synoptic overview of both texts. So, let's at least add the second text to our html overview with the wordclouds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-12T09:48:55.622Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "htmlfile2 = open(outputDir + '/Synopsis.html', encoding='utf-8', mode='w')\n",
    "\n",
    "htmlfile2.write(\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>Section Characteristics, parallel view</title>\n",
    "        <meta charset=\"utf-8\"/>\n",
    "    </head>\n",
    "    <body>\n",
    "        <table>\n",
    "\"\"\")\n",
    "spA = [[]]\n",
    "spA.clear()\n",
    "spDicts = []\n",
    "spW = []\n",
    "for i in range(0, max(len(mx_array), len(spMx_array))):\n",
    "    if (i > len(mx_array) - 1):\n",
    "        htmlfile2.write(\"\"\"\n",
    "            <tr>\n",
    "                <td>\n",
    "                    <head>Section {a}: n/a</head>\n",
    "                </td>\"\"\".format(a = str(i)))\n",
    "    else:\n",
    "        htmlfile2.write(\"\"\"\n",
    "            <tr>\n",
    "                <td>\n",
    "                    <head>Section {a}: <b>{b}</b></head><br/>\n",
    "                    <img src=\"./wc_{a}.png\"/><br/>\n",
    "                    <small><i>length: {c} words</i></small>\n",
    "                </td>\"\"\".format(a = str(i), b = label[i], c = len(tokenised[i])))\n",
    "    if (i > len(spMx_array) - 1):\n",
    "        htmlfile2.write(\"\"\"\n",
    "                <td>\n",
    "                    <head>Section {a}: n/a</head>\n",
    "                </td>\n",
    "            </tr><tr><td>&nbsp;</td></tr>\"\"\".format(a = str(i)))\n",
    "    else:\n",
    "        spA.append([ int(round(x * 100000, 0)) for x in spMx_array[i]])\n",
    "        spDicts.append(dict(zip(spFn, spA[i])))\n",
    "        spW.append(WordCloud(background_color=None, mode=\"RGBA\", \\\n",
    "                           max_font_size=40, min_font_size=10, \\\n",
    "                           max_words=60, relative_scaling=0.8).fit_words(spDicts[i]))\n",
    "        spW[i].to_file(outputDir + '/wc_' + str(i) + '_sp.png')\n",
    "        htmlfile2.write(\"\"\"\n",
    "                <td>\n",
    "                    <head>Section {d}: <b>{e}</b></head><br/>\n",
    "                    <img src=\"./wc_{d}_sp.png\"/><br/>\n",
    "                    <small><i>length: {f} words</i></small>\n",
    "                </td>\n",
    "            </tr>\n",
    "            <tr><td>&nbsp;</td></tr>\"\"\".format(d = str(i), e = spLabel[i], f = len(spTokenised[i])))\n",
    "    \n",
    "htmlfile2.write(\"\"\"\n",
    "        </table>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\")\n",
    "htmlfile2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the resulting file can be opened [here](SP_seminar/Synopsis.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T12:30:15.482766Z",
     "start_time": "2017-08-30T14:30:15.474338+02:00"
    }
   },
   "source": [
    "## Translations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe there is an approach to inter-lingual comparison after all. Here is the [API documentation](https://github.com/commonsense/conceptnet5/wiki/API) of [conceptnet.io](http://conceptnet.io), which we can use to lookup synonyms, related terms and translations. Like with such a URI:\n",
    "\n",
    "[http://api.conceptnet.io/related/c/la/rex?filter=/c/es](http://api.conceptnet.io/related/c/la/rex?filter=/c/es)\n",
    "\n",
    "We can get an identifier for a word and many possible translations for this word. So, we could - this remains to be tested in practice - look up our ten (or so) most frequent words in one language and collect all possible translations in the second language. Then we could compare these with what we actually find in the second work. How much overlap there is going to be and how univocal it is going to be remains to be seen, however..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph-based NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - [Unsupervised keywords extraction using graphs](https://graphaware.com/neo4j/2017/10/03/efficient-unsupervised-topic-extraction-nlp-neo4j.html)\n",
    "  - [Reverse Engineering Book Stories with Neo4j and GraphAware NLP](https://graphaware.com/neo4j/2017/07/24/reverse-engineering-book-stories-nlp.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - http://jonathansoma.com/lede/foundations/classes/text%20processing/tf-idf/\n",
    "  - http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/\n",
    "  - http://blog.christianperone.com/2011/10/machine-learning-text-feature-extraction-tf-idf-part-ii/\n",
    "  - https://de.dariah.eu/tatom/index.html\n",
    "  - https://stanford.edu/~rjweiss/public_html/IRiSS2013/text2/notebooks/tfidf.html\n",
    "  - http://takwatanabe.me/data_science/pyspark/cs110_lab3b.html\n",
    "  - https://github.com/mccurdyc/tf-idf/blob/master/README.md\n",
    "  - https://people.duke.edu/~ccc14/sta-663/TextProcessingExtras.html\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "245px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "2",
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
